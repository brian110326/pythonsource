{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyautogui as p\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_chrome_driver():\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 솔드아웃 상품 목록, 상세 정보 Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00CAC1C3+27395]\n\t(No symbol) [0x00C43DC4]\n\t(No symbol) [0x00B41B7F]\n\t(No symbol) [0x00B1E483]\n\t(No symbol) [0x00BAA06F]\n\t(No symbol) [0x00BBC3D6]\n\t(No symbol) [0x00BA3736]\n\t(No symbol) [0x00B77541]\n\t(No symbol) [0x00B780BD]\n\tGetHandleVerifier [0x00F63A93+2876371]\n\tGetHandleVerifier [0x00FB7F5D+3221661]\n\tGetHandleVerifier [0x00D2D634+556916]\n\tGetHandleVerifier [0x00D3474C+585868]\n\t(No symbol) [0x00C4CE04]\n\t(No symbol) [0x00C49818]\n\t(No symbol) [0x00C499B7]\n\t(No symbol) [0x00C3BF0E]\n\tBaseThreadInitThunk [0x76EBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D480CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D4809E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m browser\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0,document.body.scrollHeight)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(interval)\n\u001b[1;32m---> 19\u001b[0m cur_height \u001b[38;5;241m=\u001b[39m \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.body.scrollHeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_height \u001b[38;5;241m==\u001b[39m prev_height:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:407\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    404\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00CAC1C3+27395]\n\t(No symbol) [0x00C43DC4]\n\t(No symbol) [0x00B41B7F]\n\t(No symbol) [0x00B1E483]\n\t(No symbol) [0x00BAA06F]\n\t(No symbol) [0x00BBC3D6]\n\t(No symbol) [0x00BA3736]\n\t(No symbol) [0x00B77541]\n\t(No symbol) [0x00B780BD]\n\tGetHandleVerifier [0x00F63A93+2876371]\n\tGetHandleVerifier [0x00FB7F5D+3221661]\n\tGetHandleVerifier [0x00D2D634+556916]\n\tGetHandleVerifier [0x00D3474C+585868]\n\t(No symbol) [0x00C4CE04]\n\t(No symbol) [0x00C49818]\n\t(No symbol) [0x00C499B7]\n\t(No symbol) [0x00C3BF0E]\n\tBaseThreadInitThunk [0x76EBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D480CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D4809E+238]\n"
     ]
    }
   ],
   "source": [
    "# 솔드아웃 상품 목록, 상세 정보 crawling\n",
    "# 상위 몇개까지만 할지는 미정\n",
    "# browser.back() 적용 아직 안함\n",
    "browser = set_chrome_driver()\n",
    "result = []\n",
    "\n",
    "base_url = \"https://www.soldout.co.kr\"\n",
    "url_soldout = base_url + \"/search/product/list\"\n",
    "browser.get(url=url_soldout)\n",
    "\n",
    "# 스크롤 내리기\n",
    "interval = 3\n",
    "\n",
    "prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(interval)\n",
    "    cur_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if cur_height == prev_height:\n",
    "        break\n",
    "\n",
    "    prev_height = cur_height\n",
    "  \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "products = soup.find_all(\"div\", class_=\"product-item\")\n",
    "\n",
    "\n",
    "products = products[:1000]\n",
    "# 상품 목록 페이지에서 데이터 crawling\n",
    "for info in products:\n",
    "    # 상품 한글명\n",
    "    name_kor = info.find(\"p\", class_=\"product-name\").text\n",
    "    # 브랜드명\n",
    "    brand = info.find(\"span\", class_=\"brand-logo__text\").text\n",
    "    # 이미지 주소\n",
    "    img_tag = info.find(\"img\")\n",
    "    img_url = img_tag[\"src\"]\n",
    "    # 상세페이지 주소\n",
    "    product_detail_tag = info.find(\"a\",class_=\"link-for-seo\")\n",
    "    # https://www.soldout.co.kr/trade/detail/5534466\n",
    "    product_detail_url = base_url + product_detail_tag[\"href\"]\n",
    "\n",
    "    # 상품 상세 페이지에서 데이터 crawling\n",
    "    product_detail_url_list = []\n",
    "    product_detail_url_list.append(product_detail_url)\n",
    "\n",
    "    for url in product_detail_url_list:\n",
    "        browser.get(url=url)\n",
    "\n",
    "        # 스크롤 내리기\n",
    "        interval = 3\n",
    "        prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "            time.sleep(interval)\n",
    "            cur_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if cur_height == prev_height:\n",
    "                break\n",
    "\n",
    "            prev_height = cur_height\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "       \n",
    "        # 상품 영어명\n",
    "        name_eng = soup.select_one(\"#__layout > div > div.layout-container > div > div.item-container__in > div.container-right > div.item_info__wrap > p\")\n",
    "        # 모델번호\n",
    "        model_no = soup.select_one(\"#__layout > div > div.layout-container > div > div.item-container__in > div.container-right > div:nth-child(8) > dl:nth-child(3) > dd\")\n",
    "        # 출시일(DataFrame에서 날짜형태로 바꾸기)\n",
    "        release_date = soup.select_one(\"#__layout > div > div.layout-container > div > div.item-container__in > div.container-right > div:nth-child(8) > dl:nth-child(4) > dd\")\n",
    "        # 색상\n",
    "        color = soup.select_one(\"#__layout > div > div.layout-container > div > div.item-container__in > div.container-right > div:nth-child(8) > dl.product-info__dl.color > dd\")\n",
    "        # 원래 가격(\"원\" 제거 후 DataFrame에서 int형으로 바꾸기)\n",
    "        original_price = soup.select_one(\"#__layout > div > div.layout-container > div > div.item-container__in > div.container-right > div:nth-child(8) > dl:nth-child(6) > dd\")\n",
    "\n",
    "        if name_eng and model_no and release_date and color and original_price:\n",
    "            name_eng = name_eng.text\n",
    "            model_no = model_no.text\n",
    "            release_date = release_date.text\n",
    "            color = color.text\n",
    "            original_price = original_price.text\n",
    "        else:\n",
    "            name_eng = np.nan\n",
    "            model_no = np.nan\n",
    "            release_date = np.nan\n",
    "            color = np.nan\n",
    "            original_price = np.nan\n",
    "\n",
    "        # print(brand, name_kor, name_eng, model_no, release_date, color, original_price, img_url, product_detail_url)\n",
    "\n",
    "    result.append([brand, name_kor, name_eng, model_no, release_date, color, original_price, img_url, product_detail_url])\n",
    "\n",
    "columns = [\"Brand\", \"Name_Kor\", \"Name_Eng\", \"Model_No\", \"Release_Date\", \"Color\", \"Original_Price\", \"Image_URL\", \"Product_Detail_URL\"]\n",
    "df = pd.DataFrame(result, columns=columns)\n",
    "df.to_excel(\"./data/soldout_products2.xlsx\", index=False)\n",
    "\n",
    "wb = load_workbook(\"./data/soldout_products2.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "# 열의 너비 설정\n",
    "ws.column_dimensions[\"A\"].width = 20\n",
    "ws.column_dimensions[\"B\"].width = 100\n",
    "ws.column_dimensions[\"C\"].width = 100\n",
    "ws.column_dimensions[\"D\"].width = 50\n",
    "ws.column_dimensions[\"E\"].width = 50\n",
    "ws.column_dimensions[\"F\"].width = 50\n",
    "ws.column_dimensions[\"G\"].width = 50\n",
    "ws.column_dimensions[\"H\"].width = 100\n",
    "ws.column_dimensions[\"I\"].width = 60\n",
    "\n",
    "# 최종 엑셀 파일로 저장\n",
    "wb.save(\"./data/soldout_products2.xlsx\")\n",
    "\n",
    "print(len(products))\n",
    "print(\"엑셀 파일로 저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 솔드아웃 거래내역 Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".btn-show-all\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00DAC1C3+27395]\n\t(No symbol) [0x00D43DC4]\n\t(No symbol) [0x00C41B7F]\n\t(No symbol) [0x00C82C65]\n\t(No symbol) [0x00C82D3B]\n\t(No symbol) [0x00CBEC82]\n\t(No symbol) [0x00CA39E4]\n\t(No symbol) [0x00CBCB24]\n\t(No symbol) [0x00CA3736]\n\t(No symbol) [0x00C77541]\n\t(No symbol) [0x00C780BD]\n\tGetHandleVerifier [0x01063A93+2876371]\n\tGetHandleVerifier [0x010B7F5D+3221661]\n\tGetHandleVerifier [0x00E2D634+556916]\n\tGetHandleVerifier [0x00E3474C+585868]\n\t(No symbol) [0x00D4CE04]\n\t(No symbol) [0x00D49818]\n\t(No symbol) [0x00D499B7]\n\t(No symbol) [0x00D3BF0E]\n\tBaseThreadInitThunk [0x75D7FCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x774180CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x7741809E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 거래내역 전체보기 버튼 클릭\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m view_all_btn \u001b[38;5;241m=\u001b[39m \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbtn-show-all\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m view_all_btn\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     45\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\source\\pythonsource\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".btn-show-all\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00DAC1C3+27395]\n\t(No symbol) [0x00D43DC4]\n\t(No symbol) [0x00C41B7F]\n\t(No symbol) [0x00C82C65]\n\t(No symbol) [0x00C82D3B]\n\t(No symbol) [0x00CBEC82]\n\t(No symbol) [0x00CA39E4]\n\t(No symbol) [0x00CBCB24]\n\t(No symbol) [0x00CA3736]\n\t(No symbol) [0x00C77541]\n\t(No symbol) [0x00C780BD]\n\tGetHandleVerifier [0x01063A93+2876371]\n\tGetHandleVerifier [0x010B7F5D+3221661]\n\tGetHandleVerifier [0x00E2D634+556916]\n\tGetHandleVerifier [0x00E3474C+585868]\n\t(No symbol) [0x00D4CE04]\n\t(No symbol) [0x00D49818]\n\t(No symbol) [0x00D499B7]\n\t(No symbol) [0x00D3BF0E]\n\tBaseThreadInitThunk [0x75D7FCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x774180CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x7741809E+238]\n"
     ]
    }
   ],
   "source": [
    "# 솔드아웃 로그인\n",
    "browser = set_chrome_driver()\n",
    "browser.get(url_soldout)\n",
    "result2 = []\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "login_button = browser.find_element(By.XPATH, '//*[@id=\"__layout\"]/div/div[1]/header/div/ul/li[1]/a')\n",
    "login_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "id_input = browser.find_element(By.CSS_SELECTOR, \"#__layout > div > div.layout-container > div > form > div:nth-child(1) > div > input\")\n",
    "id_input.send_keys(\"uj05273\")\n",
    "\n",
    "pwd_input = browser.find_element(By.CSS_SELECTOR, \"#__layout > div > div.layout-container > div > form > div:nth-child(2) > div > input\")\n",
    "pwd_input.send_keys(\"brian981103\")\n",
    "\n",
    "signin_button = browser.find_element(By.CLASS_NAME, \"btn-primary\")\n",
    "signin_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# 거래내역 crawling\n",
    "for info in products[:100]:\n",
    "    # 상세페이지 주소\n",
    "    product_detail_tag = info.find(\"a\",class_=\"link-for-seo\")\n",
    "    # https://www.soldout.co.kr/trade/detail/5534466\n",
    "    product_detail_url = base_url + product_detail_tag[\"href\"]\n",
    "\n",
    "    # 상품 상세 페이지에서 데이터 crawling\n",
    "    product_detail_url_list = []\n",
    "    product_detail_url_list.append(product_detail_url)\n",
    "\n",
    "    for url in product_detail_url_list:\n",
    "        #print(url)\n",
    "        browser.get(url=url)\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "        # 거래내역 전체보기 버튼 클릭\n",
    "        view_all_btn = browser.find_element(By.CLASS_NAME, \"btn-show-all\")\n",
    "        view_all_btn.click()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 상품 목록 데이터 중 한글이름과 merge 하기 위함\n",
    "        name_kor = soup.find(\"p\",class_=\"name_kor\")\n",
    "        if name_kor:\n",
    "            name_kor = name_kor.text\n",
    "        \n",
    "        # 스크롤을 위해 마우스 중앙으로 옮기기\n",
    "        p.moveTo(1270,815,0.5)\n",
    "        p.click()\n",
    "\n",
    "        modal_content = browser.find_element(By.CSS_SELECTOR, \"body > div.trade_modal.BaseModal > div > div > div.base-table.trade_modal__table.modal-table > table > tbody\")\n",
    "        prev_height = browser.execute_script(\"return arguments[0].scrollHeight\", modal_content)\n",
    "\n",
    "        # 모달 창 스크롤 내리기\n",
    "        while True:\n",
    "            browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", modal_content)\n",
    "            time.sleep(1)\n",
    "            cur_height = browser.execute_script(\"return arguments[0].scrollHeight\", modal_content)\n",
    "\n",
    "            if cur_height == prev_height:\n",
    "                break\n",
    "\n",
    "            prev_height = cur_height\n",
    "        \n",
    "        soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "        trades = soup.select(\"body > div.trade_modal.BaseModal > div > div > div.base-table.trade_modal__table.modal-table > table > tbody > tr\")\n",
    "        \n",
    "        for trade in trades:\n",
    "            trade_dates = trade.select_one(\"tbody > tr > td:nth-child(1)\")\n",
    "            trade_sizes = trade.select_one(\"tbody > tr > td:nth-child(2)\")\n",
    "            trade_prices = trade.select_one(\"tbody > tr > td:nth-child(3) > span\")\n",
    "\n",
    "            if trade_dates and trade_sizes and trade_prices:\n",
    "                trade_dates = trade_dates.text\n",
    "                trade_sizes = trade_sizes.text\n",
    "                trade_prices = trade_prices.text\n",
    "        \n",
    "            result2.append([name_kor,trade_dates,trade_sizes,trade_prices])\n",
    "\n",
    "\n",
    "columns = [\"Name_Kor\", \"Trade_Dates\", \"Trade_Sizes\", \"Trade_Prices\"]\n",
    "df = pd.DataFrame(result2, columns=columns)\n",
    "df.to_excel(\"./data/soldout_trades2.xlsx\", index=False)\n",
    "\n",
    "wb = load_workbook(\"./data/soldout_trades2.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "# 열의 너비 설정\n",
    "ws.column_dimensions[\"A\"].width = 50\n",
    "ws.column_dimensions[\"B\"].width = 35\n",
    "ws.column_dimensions[\"C\"].width = 30\n",
    "ws.column_dimensions[\"D\"].width = 30\n",
    "\n",
    "wb.save(\"./data/soldout_trades2.xlsx\")\n",
    "\n",
    "print(len(products))\n",
    "print(\"엑셀 파일로 저장 완료!\")\n",
    "            \n",
    "    # X버튼으로 나가기 -> 뒤로가기 버튼\n",
    "    # x_btn = browser.find_element(By.XPATH,'/html/body/div[5]/div/header/div[3]/button')\n",
    "    # x_btn.click()\n",
    "    # browser.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kream에서 상품 상세페이지, 상품코드 crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://kream.co.kr/products/307550', 'https://kream.co.kr/products/21935', 'https://kream.co.kr/products/12831', 'https://kream.co.kr/products/15251', 'https://kream.co.kr/products/247226', 'https://kream.co.kr/products/288640', 'https://kream.co.kr/products/28260', 'https://kream.co.kr/products/58293', 'https://kream.co.kr/products/244293', 'https://kream.co.kr/products/310709', 'https://kream.co.kr/products/67193', 'https://kream.co.kr/products/137241', 'https://kream.co.kr/products/34146', 'https://kream.co.kr/products/114316', 'https://kream.co.kr/products/304900', 'https://kream.co.kr/products/58291', 'https://kream.co.kr/products/15248', 'https://kream.co.kr/products/262947', 'https://kream.co.kr/products/297522', 'https://kream.co.kr/products/306357', 'https://kream.co.kr/products/219423', 'https://kream.co.kr/products/284030', 'https://kream.co.kr/products/36038', 'https://kream.co.kr/products/97779', 'https://kream.co.kr/products/90805', 'https://kream.co.kr/products/240723', 'https://kream.co.kr/products/107805', 'https://kream.co.kr/products/98602', 'https://kream.co.kr/products/306198', 'https://kream.co.kr/products/266889', 'https://kream.co.kr/products/301005', 'https://kream.co.kr/products/306356', 'https://kream.co.kr/products/216897', 'https://kream.co.kr/products/129482', 'https://kream.co.kr/products/284029', 'https://kream.co.kr/products/277480', 'https://kream.co.kr/products/58287', 'https://kream.co.kr/products/306454', 'https://kream.co.kr/products/13100', 'https://kream.co.kr/products/36', 'https://kream.co.kr/products/59834', 'https://kream.co.kr/products/311052', 'https://kream.co.kr/products/15889', 'https://kream.co.kr/products/190148', 'https://kream.co.kr/products/23928', 'https://kream.co.kr/products/232746', 'https://kream.co.kr/products/114028', 'https://kream.co.kr/products/101218', 'https://kream.co.kr/products/229945', 'https://kream.co.kr/products/26344']\n"
     ]
    }
   ],
   "source": [
    "browser = set_chrome_driver()\n",
    "base_url = \"https://kream.co.kr\"\n",
    "url = base_url + \"/search\"\n",
    "browser.get(url=url)\n",
    "\n",
    "time.sleep(3)\n",
    "result = []\n",
    "\n",
    "# 스크롤 내리기\n",
    "# interval = 3\n",
    "# prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# while True:\n",
    "#     browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "#     time.sleep(interval)\n",
    "#     cur_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#     if cur_height == prev_height:\n",
    "#         break\n",
    "\n",
    "#     prev_height = cur_height\n",
    "\n",
    "# time.sleep(4)\n",
    "\n",
    "# 상품마다 각 상세 페이지 가져오기\n",
    "soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "products = soup.find_all(\"div\",class_=\"search_result_item product\")\n",
    "\n",
    "\n",
    "\n",
    "product_detail_url_list = []\n",
    "\n",
    "for product in products:\n",
    "    \n",
    "    product_detail_url = product.find(\"a\",class_=\"item_inner\")[\"href\"]\n",
    "    # print(\"product_detail_url \",product_detail_url)\n",
    "    product_detail_urls = base_url + product_detail_url\n",
    "    \n",
    "    # 상품 상세 페이지에서 데이터 crawling\n",
    "    product_detail_url_list.append(product_detail_urls)\n",
    "\n",
    "print(product_detail_url_list)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url https://kream.co.kr/products/288640\n",
      "model_no  DZ4137-700\n",
      "social_url https://kream.co.kr/social/products/26344\n",
      "20\n",
      "엑셀 파일로 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "for url in product_detail_url_list[5:6]:\n",
    "    \n",
    "    print(\"url {}\".format(url))\n",
    "\n",
    "    browser.get(url=url)\n",
    "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "    model_no = soup.select_one(\"div.product_info_wrap > div > dl > div:nth-child(3) > div.product_info\")\n",
    "    if model_no:\n",
    "        model_no = model_no.text.strip()\n",
    "        print(\"model_no \",model_no)\n",
    "\n",
    "    prouct_detail_url = url.split(\"/\")\n",
    "     = urls[0]+\"/social\"+\n",
    "\n",
    "    # https://kream.co.kr/social/products/12831\n",
    "    social_url = base_url + \"/social\" + product_detail_url\n",
    "    print(\"social_url {}\".format(social_url))\n",
    "\n",
    "    browser.get(url=social_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 리뷰 전체를 보기위하여 스크롤 내리기\n",
    "    interval = 3\n",
    "    prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(interval)\n",
    "        cur_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if cur_height == prev_height:\n",
    "            break\n",
    "\n",
    "\n",
    "        prev_height = cur_height\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "    socials = soup.find_all(\"div\",class_=\"feed_card\")\n",
    "    print(len(socials))\n",
    "\n",
    "    for social in socials:\n",
    "        social_text = social.find(\"p\",class_=\"text_box\")\n",
    "        if social_text:\n",
    "            social_text = social_text.text\n",
    "        else:\n",
    "            social_text = np.nan\n",
    "        result.append([model_no,social_text])\n",
    "\n",
    "\n",
    "\n",
    "columns = [\"Model_No\",\"Social_Text\"]\n",
    "df = pd.DataFrame(result, columns=columns)\n",
    "df.to_excel(\"./data/kream_social_text_text.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"엑셀 파일로 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 기본템으로 좋음 </p> 기본템으로 좋음\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #비오는날코디 #썸머룩 #여름스타일 #stussy </p> #비오는날코디 #썸머룩 #여름스타일 #stussy\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 1위제품들로만 구성한 커플룩! </p> 1위제품들로만 구성한 커플룩!\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #핫트렌드챌린지 #페스티벌룩 #썸머코디 #사이즈팁 #휴가준비 #스타일공유 #트렌드슈즈 #KICKS #여름데일리 #여름신발 </p> #핫트렌드챌린지 #페스티벌룩 #썸머코디 #사이즈팁 #휴가준비 #스타일공유 #트렌드슈즈 #KICKS #여름데일리 #여름신발\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 여름이라도 올블랙 </p> 여름이라도 올블랙\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 야레야레 못말리는 아가씨 </p> 야레야레 못말리는 아가씨\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #핫트렌드챌린지 #페스티벌룩 #썸머코디 #휴가준비 #스타일공유 #여름데일리 #ootd </p> #핫트렌드챌린지 #페스티벌룩 #썸머코디 #휴가준비 #스타일공유 #여름데일리 #ootd\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 스투시 </p> 스투시\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 헤헤 나도 스투시 샀당 </p> 헤헤 나도 스투시 샀당\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> STÜSSY 👤 PÄTTA  BLK </p> STÜSSY 👤 PÄTTA  BLK\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 스투시xl 성공 184 90 </p> 스투시xl 성공 184 90\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> STUSSY 👣 BLACK </p> STUSSY 👣 BLACK\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 커플티로 굿이네유~ </p> 커플티로 굿이네유~\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 반팔티 top10 최애 옷 입히기 </p> 반팔티 top10 최애 옷 입히기\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #핫트렌드챌린지 </p> #핫트렌드챌린지\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 올블랙 덥다! (*^ω^*)\n",
      "\n",
      " #핫트렌드챌린지 #닥터마틴챌린지 #여름아이템 #스니커즈추천 #여름휴가 #KICKS #썸머데일리 #최애신발 #스타일컬렉터 #나이키꼼데가르송 #스투시 #스투시반팔 </p> 올블랙 덥다! (*^ω^*)\n",
      "\n",
      " #핫트렌드챌린지 #닥터마틴챌린지 #여름아이템 #스니커즈추천 #여름휴가 #KICKS #썸머데일리 #최애신발 #스타일컬렉터 #나이키꼼데가르송 #스투시 #스투시반팔\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #핫트렌드챌린지 #여름아이템 </p> #핫트렌드챌린지 #여름아이템\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 비온다 외식하자 </p> 비온다 외식하자\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 스투시 기본티 코디 드가자~ </p> 스투시 기본티 코디 드가자~\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #닥터마틴챌린지 #KICKS #썸머데일리 </p> #닥터마틴챌린지 #KICKS #썸머데일리\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 삼길포는 회덮밥&amp;물회지 </p> 삼길포는 회덮밥&물회지\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 뜨거운 여름이닷! </p> 뜨거운 여름이닷!\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 세상편한신발이 핫한법 </p> 세상편한신발이 핫한법\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 더우 </p> 더우\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 여름이다☀️🥵 </p> 여름이다☀️🥵\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 165/66 M 딱입니다 </p> 165/66 M 딱입니다\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #닥터마틴챌린지 </p> #닥터마틴챌린지\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 🖤 </p> 🖤\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> s사이즈 </p> s사이즈\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #기아타이거즈 #기아타이거즈찐팬 #스투시 </p> #기아타이거즈 #기아타이거즈찐팬 #스투시\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 너무너무너무 이뻤어요 흰색 사고 싶었는데 뭐 흘리고 묻히고 그럴까봐 엄청난 고민끝에 산건데 너무 잘 산거같아요 역시 돈값합니더  ♡ </p> 너무너무너무 이뻤어요 흰색 사고 싶었는데 뭐 흘리고 묻히고 그럴까봐 엄청난 고민끝에 산건데 너무 잘 산거같아요 역시 돈값합니더  ♡\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #여름준비챌린지 #썸머스타일 2XL 굿 </p> #여름준비챌린지 #썸머스타일 2XL 굿\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #여름준비챌린지 #썸머스타일 #신발추천 #KICKS #여름코디 #ootd #시험기간코디 #시험기간룩 #버뮤다 #버뮤다팬츠 #버뮤다팬츠코디 </p> #여름준비챌린지 #썸머스타일 #신발추천 #KICKS #여름코디 #ootd #시험기간코디 #시험기간룩 #버뮤다 #버뮤다팬츠 #버뮤다팬츠코디\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #stussy #salomon #XAPRO3D #여름코디 #썸머스타일 </p> #stussy #salomon #XAPRO3D #여름코디 #썸머스타일\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 스투시 미쳐서 오사카&amp;서울 매장투어 결과물 내사이즈 힘들게 구했네 ㅋㅋㅋㅋ #여름준비챌린지 #썸머스타일 </p> 스투시 미쳐서 오사카&서울 매장투어 결과물 내사이즈 힘들게 구했네 ㅋㅋㅋㅋ #여름준비챌린지 #썸머스타일\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 폼은 작고 기장만 넘 길다... 한치수 더 크게 입는게 나겠다 </p> 폼은 작고 기장만 넘 길다... 한치수 더 크게 입는게 나겠다\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 여성분들 사이즈 팁 </p> 여성분들 사이즈 팁\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> . </p> .\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #여름준비챌린지 </p> #여름준비챌린지\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 외출띠 </p> 외출띠\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 여자친구랑 같이 입으려구 샀어용 !! </p> 여자친구랑 같이 입으려구 샀어용 !!\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #여름준비챌린지 </p> #여름준비챌린지\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #오오티디 #stussycap  #stussylover #스투시반팔 #스투시 #스투시 </p> #오오티디 #stussycap  #stussylover #스투시반팔 #스투시 #스투시\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 엘베샷은 못참쥐3 </p> 엘베샷은 못참쥐3\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 쇠질엔 조던💪 </p> 쇠질엔 조던💪\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 키170 몸무게 75\n",
      "배나온 아재스타일인데 xl보다는 L사이즈를 입어야 한다는걸을 30만원 가까이 쓰고나서 알게됐다..스투시는 사이즈 맞춰 입기 너무어려워ㅡㅡ\n",
      "\n",
      "옷은 잘 못이 없었다 내 몸뚱아리에 문제가 있었지..\n",
      "\n",
      "Stussy Tough Gear T-Shirt Ocean XL(완전 오버핏_하의실종핏)\n",
      "\n",
      "Stussy Basic Stussy T-Shirt Midnight 2024는 L(그냥박스티)\n",
      "\n",
      "Stussy 8 Ball Pigment Dyed T-Shirt Olive도 L(세미 오버핏)\n",
      "#스투시 #여름맞이 #사이즈팁 #오버핏 </p> 키170 몸무게 75\n",
      "배나온 아재스타일인데 xl보다는 L사이즈를 입어야 한다는걸을 30만원 가까이 쓰고나서 알게됐다..스투시는 사이즈 맞춰 입기 너무어려워ㅡㅡ\n",
      "\n",
      "옷은 잘 못이 없었다 내 몸뚱아리에 문제가 있었지..\n",
      "\n",
      "Stussy Tough Gear T-Shirt Ocean XL(완전 오버핏_하의실종핏)\n",
      "\n",
      "Stussy Basic Stussy T-Shirt Midnight 2024는 L(그냥박스티)\n",
      "\n",
      "Stussy 8 Ball Pigment Dyed T-Shirt Olive도 L(세미 오버핏)\n",
      "#스투시 #여름맞이 #사이즈팁 #오버핏\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #스투시반팔 #상품샷 #KREAM스타일 #여름코디 #이쁘네 #요즘스타일 </p> #스투시반팔 #상품샷 #KREAM스타일 #여름코디 #이쁘네 #요즘스타일\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 오운완💪 </p> 오운완💪\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 일본~ 🇯🇵 </p> 일본~ 🇯🇵\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 🌅 </p> 🌅\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> Stussy~~~~\n",
      "🏴‍☠️🏴‍☠️ </p> Stussy~~~~\n",
      "🏴‍☠️🏴‍☠️\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 엘베샷은 못참지2 </p> 엘베샷은 못참지2\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 🖤 </p> 🖤\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 젊게 티내기 </p> 젊게 티내기\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 가천대 blue day 🫶🫶🫶 </p> 가천대 blue day 🫶🫶🫶\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #여름준비 #스투시 #발렌시아가 #러너스니커즈 #반팔티셔츠 </p> #여름준비 #스투시 #발렌시아가 #러너스니커즈 #반팔티셔츠\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 내일은 이거다 🍊💜 </p> 내일은 이거다 🍊💜\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 피시방 알바 #ootd 붿 생각보다 편해요..ㅎㅎ\n",
      "\n",
      "#스투시 #스투시반팔 #에어포스1쉐도우 </p> 피시방 알바 #ootd 붿 생각보다 편해요..ㅎㅎ\n",
      "\n",
      "#스투시 #스투시반팔 #에어포스1쉐도우\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 스투시 괌 추가좀..🇬🇺 </p> 스투시 괌 추가좀..🇬🇺\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 첫 셀프스튜디오 성공적♥︎ </p> 첫 셀프스튜디오 성공적♥︎\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> Knu vans 넘 귀업잖아~ </p> Knu vans 넘 귀업잖아~\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 178.63.  M사이즈가 딱 정사이즈 입니다 </p> 178.63.  M사이즈가 딱 정사이즈 입니다\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 동생과 투샷  사카이&amp;스투시 👍👍👍 </p> 동생과 투샷  사카이&스투시 👍👍👍\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 제주 가고싶다! ꉂ (๑¯ਊ¯)σ л̵ʱªʱªʱª\n",
      "\n",
      " #프레피룩챌린지 #여름대비 #사이즈팁 #데일리신발 #스트릿템 #봄캐주얼 #스투시 #스투시반팔 #미하라 #미하라야스히로 #미하라야스히로블레이키 #스트릿코디 </p> 제주 가고싶다! ꉂ (๑¯ਊ¯)σ л̵ʱªʱªʱª\n",
      "\n",
      " #프레피룩챌린지 #여름대비 #사이즈팁 #데일리신발 #스트릿템 #봄캐주얼 #스투시 #스투시반팔 #미하라 #미하라야스히로 #미하라야스히로블레이키 #스트릿코디\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 제주도 </p> 제주도\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #ootd </p> #ootd\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> #데일리룩 #롱슬리브 </p> #데일리룩 #롱슬리브\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 오사카에서 득템 </p> 오사카에서 득템\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 쇼핑은 즐겁띠예 </p> 쇼핑은 즐겁띠예\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 새벽감성컷😎🔥 </p> 새벽감성컷😎🔥\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 🙉 </p> 🙉\n",
      "<p class=\"text_box\" data-v-333cb905=\"\"> 첫 스투시👕🔥 </p> 첫 스투시👕🔥\n"
     ]
    }
   ],
   "source": [
    "browser = set_chrome_driver()\n",
    "social_url='https://kream.co.kr/social/products/247226'\n",
    "browser.get(url=social_url)\n",
    "time.sleep(3)\n",
    "\n",
    "result = []\n",
    "\n",
    "# 리뷰 전체를 보기위하여 스크롤 내리기\n",
    "interval = 3\n",
    "prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(interval)\n",
    "    cur_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if cur_height == prev_height:\n",
    "        break\n",
    "\n",
    "    prev_height = cur_height\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "# socials = soup.find_all(\"div\",class_=\"feed_card\")\n",
    "# print(len(socials))\n",
    "\n",
    "socials = soup.select(\"div.card_detail > p\")\n",
    "print(len(socials))\n",
    "\n",
    "for social in socials:\n",
    "    # social_text = social.find(\"p\",class_=\"text_box\")\n",
    "    # if social_text:\n",
    "    #     social_text = social_text.text        \n",
    "    # else:\n",
    "    #     social_text = np.nan\n",
    "    print(social,social.string.strip())\n",
    "    result.append([model_no,social.string.strip()])\n",
    "\n",
    "\n",
    "columns = [\"Model_No\",\"Social_Text\"]\n",
    "df = pd.DataFrame(result, columns=columns)\n",
    "df.to_excel(\"./data/kream_social_text_text.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
