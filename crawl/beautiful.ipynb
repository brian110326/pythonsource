{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "- parser(html, xml의 형태로 내려온 데이터를 원하는 형태의 구조로 변환)\n",
    "- requests + bs4 : 이 조합으로 주로 crawling\n",
    "- parser 종류\n",
    "    - html.parser\n",
    "    - lxml(parser 속도 가장 빠름)\n",
    "    - html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>'손흥민의 힘'인가, 토트넘이 아스널을 제쳤다, 영국이 놀랐다!…구단 가치 '4조3790억'+전세계 8위</title>\n",
      "<h3 class=\"tit_view\" data-translation=\"true\">'손흥민의 힘'인가, 토트넘이 아스널을 제쳤다, 영국이 놀랐다!…구단 가치 '4조3790억'+전세계 8위</h3>\n",
      "'손흥민의 힘'인가, 토트넘이 아스널을 제쳤다, 영국이 놀랐다!…구단 가치 '4조3790억'+전세계 8위\n",
      "{'class': ['tit_view'], 'data-translation': 'true'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524104635723\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # 요소접근\n",
    "    # 태그명 사용\n",
    "    print(soup.title)\n",
    "    print(soup.h3)\n",
    "    # 태그의 text 추출\n",
    "    print(soup.title.get_text())\n",
    "    print(soup.h3.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n",
      "The Dormouse's story\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "\n",
      "<p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "['The', \"Dormouse's\", 'story']\n",
      "{'class': ['title']}\n",
      "['title']\n",
      "\n",
      "<b> The Dormouse's story </b>\n",
      " The Dormouse's story \n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    title = soup.title\n",
    "    print(title)\n",
    "    print(title.get_text())\n",
    "    print(title.string)\n",
    "    print(title.parent)\n",
    "    print()\n",
    "    p1 = soup.p\n",
    "    print(p1)\n",
    "    print(p1.get_text().split())\n",
    "    print(p1.attrs)\n",
    "    print(p1[\"class\"])\n",
    "\n",
    "    print()\n",
    "    \n",
    "    b = soup.b\n",
    "    print(b)\n",
    "    print(b.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "       Elsie \n",
      "      ,\n",
      "       Lacie \n",
      "      and\n",
      "       Tillie \n",
      "      ; and they lived at the bottom of a well.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(p2)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(p2\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m())\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(p2\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(p2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# 문서의 구조를 이용한 요소 찾기\n",
    "# parent, children, next_sibling.....\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "\n",
    "    # body = soup.body\n",
    "    # print(f\"body children {body.children}\")\n",
    "    # for child in body.children:\n",
    "    #     print(child)\n",
    "\n",
    "    # 첫번째 p 요소 찾기\n",
    "    p1 = soup.p\n",
    "    p2 = p1.find_next_sibling(\"p\")\n",
    "    print(p2)\n",
    "    print(p2.get_text().strip())\n",
    "    print(p2.string.strip())\n",
    "    print(p2.attrs)\n",
    "    print(p2[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "<p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "<p class=\"story\">...</p>\n",
      "================================================================================\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "http://example.com/tillie\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n"
     ]
    }
   ],
   "source": [
    "# find() : 조건을 만족하는 요소 1개 찾기\n",
    "# find_all() : 조건을 만족하는 요소 모두 찾기\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "\n",
    "    head = soup.find(name=\"head\")\n",
    "    print(head)\n",
    "\n",
    "    # p1 = soup.find(\"p\")\n",
    "    # print(p1)\n",
    "\n",
    "    p1 = soup.find(\"p\", attrs={\"class\":\"title\"})\n",
    "    print(p1)\n",
    "\n",
    "    p2 = soup.find(\"p\",class_=\"story\")\n",
    "    print(p2)\n",
    "\n",
    "    p_all = soup.find_all(\"p\",class_=\"story\")\n",
    "    print(p_all[1])\n",
    "\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    a1 = soup.find(\"a\", attrs={\"id\":\"link1\"})\n",
    "    print(a)\n",
    "\n",
    "    a3 = soup.find(\"a\",id=\"link3\")\n",
    "    print(a3[\"href\"])\n",
    "\n",
    "    a_tags = soup.find_all(\"a\", limit=2)\n",
    "    for ele in a_tags:\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elsie', 'Lacie', 'Tillie']\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "\n",
    "    link1 = soup.find_all(string=[\"Elsie\", \"Lacie\",\"Tillie\"])\n",
    "    link2 = soup.find_all(\"a\",string=[\"Elsie\", \"Lacie\",\"Tillie\"])\n",
    "    print(link1)\n",
    "    print(link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n",
      "\n",
      "Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news.\n",
      "If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer.\n",
      "Heavens! what a virulent attack!\n",
      "First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest,\n",
      "Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling?\n",
      "You are\n",
      "staying the whole evening, I hope?\n",
      "And the fete at the English ambassador's? Today is Wednesday. I\n",
      "must put in an appearance there,\n",
      "My daughter is\n",
      "coming for me to take me there.\n",
      "I thought today's fete had been canceled. I confess all these\n",
      "festivities and fireworks are becoming wearisome.\n",
      "If they had known that you wished it, the entertainment would\n",
      "have been put off,\n",
      "Don't tease! Well, and what has been decided about Novosiltsev's\n",
      "dispatch? You know everything.\n",
      "What can one say about it?\n",
      "What has been decided? They have decided that\n",
      "Buonaparte has burnt his boats, and I believe that we are ready to\n",
      "burn ours.\n",
      "Oh, don't speak to me of Austria. Perhaps I don't understand\n",
      "things, but Austria never has wished, and does not wish, for war.\n",
      "She is betraying us! Russia alone must save Europe. Our gracious\n",
      "sovereign recognizes his high vocation and will be true to it. That is\n",
      "the one thing I have faith in! Our good and wonderful sovereign has to\n",
      "perform the noblest role on earth, and he is so virtuous and noble\n",
      "that God will not forsake him. He will fulfill his vocation and\n",
      "crush the hydra of revolution, which has become more terrible than\n",
      "ever in the person of this murderer and villain! We alone must\n",
      "avenge the blood of the just one.... Whom, I ask you, can we rely\n",
      "on?... England with her commercial spirit will not and cannot\n",
      "understand the Emperor Alexander's loftiness of soul. She has\n",
      "refused to evacuate Malta. She wanted to find, and still seeks, some\n",
      "secret motive in our actions. What answer did Novosiltsev get? None.\n",
      "The English have not understood and cannot understand the\n",
      "self-abnegation of our Emperor who wants nothing for himself, but only\n",
      "desires the good of mankind. And what have they promised? Nothing! And\n",
      "what little they have promised they will not perform! Prussia has\n",
      "always declared that Buonaparte is invincible, and that all Europe\n",
      "is powerless before him.... And I don't believe a word that Hardenburg\n",
      "says, or Haugwitz either. This famous Prussian neutrality is just a\n",
      "trap. I have faith only in God and the lofty destiny of our adored\n",
      "monarch. He will save Europe!\n",
      "I think,\n",
      "None\n",
      "In a moment. A propos,\n",
      "None\n",
      "I shall be delighted to meet them,\n",
      "But tell me,\n",
      "is it true that the Dowager Empress wants Baron Funke\n",
      "to be appointed first secretary at Vienna? The baron by all accounts\n",
      "is a poor creature.\n",
      "Baron Funke has been recommended to the Dowager Empress by her\n",
      "sister,\n",
      "Now about your family. Do you know that since your daughter came\n",
      "out everyone has been enraptured by her? They say she is amazingly\n",
      "beautiful.\n",
      "I often think,\n",
      "None\n",
      "Two such charming children. And really you appreciate\n",
      "them less than anyone, and so you don't deserve to have them.\n",
      "I can't help it,\n",
      "Lavater would have said I\n",
      "lack the bump of paternity.\n",
      "Don't joke; I mean to have a serious talk with you. Do you know I\n",
      "am dissatisfied with your younger son? Between ourselves\n",
      "he was mentioned at Her\n",
      "Majesty's and you were pitied....\n",
      "What would you have me do?\n",
      "You know I did all\n",
      "a father could for their education, and they have both turned out\n",
      "fools. Hippolyte is at least a quiet fool, but Anatole is an active\n",
      "one. That is the only difference between them.\n",
      "And why are children born to such men as you? If you were not a\n",
      "father there would be nothing I could reproach you with,\n",
      "I am your faithful slave and to you alone I can confess that my\n",
      "children are the bane of my life. It is the cross I have to bear. That\n",
      "is how I explain it to myself. It can't be helped!\n"
     ]
    }
   ],
   "source": [
    "# https://pythonscraping.com/pages/warandpeace.html\n",
    "url = \"https://pythonscraping.com/pages/warandpeace.html\"\n",
    "# 등장인물 출력\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    characters = soup.find_all(\"span\", attrs={\"class\":\"green\"})\n",
    "    for character in characters:\n",
    "        print(character.string)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    lines = soup.find_all(\"span\", attrs={\"class\":\"red\"})\n",
    "    for line in lines:\n",
    "        print(line.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'손흥민의 힘'인가, 토트넘이 아스널을 제쳤다, 영국이 놀랐다!…구단 가치 '4조3790억'+전세계 8위\n",
      "나승우 기자\n",
      "2024. 5. 24. 10:46\n",
      "(엑스포츠뉴스 나승우 기자) 우승컵 하나 없어도 전 세계 8위가 될 수 있다. 토트넘 홋스퍼가 첼시, 아스널 등 라이벌들을 제치고 전 세계 구단 가치 8위에 올랐다.\n",
      "(엑스포츠뉴스 나승우 기자) 우승컵 하나 없어도 전 세계 8위가 될 수 있다. 토트넘 홋스퍼가 첼시, 아스널 등 라이벌들을 제치고 전 세계 구단 가치 8위에 올랐다.\n",
      "미국 포브스는 23일(한국시간) \"유럽 전역의 TV 중계 역풍에도 불구하고 팀 형균 자산 가치는 23억 달러(약 3조 1475억원)로 지난해보다 5.1% 증가했다\"라며 전 세계 구단 가치 TOP 10을 공개했다.\n",
      "세계 최고의 명문 레알 마드리드(스페인)가 66억 달러(약 9조321억원)로 1위에 오른 가운데 손흥민이 뛰고 있는 토트넘은 8위에 해당하는 것으로 나타났다.\n",
      "매체에 따르면 토트넘의 구단 가치는 32억 달러(약 4조3792억원)로 지난해에 비해 14%나 올랐다. 영업 이익은 1억 6100만 달러(약 2203억원)였다.\n",
      "44억 달러(약 6조214억원)의 파리 생제르맹(PSG) 뒤를 이은 것으로 런던 라이벌 아스널, 첼시를 모두 제쳤다. 첼시가 31억 달러(약 4조2423억원)로 9위, 아스널은 26억 달러(약 3조 5581억원)로 10위였다.\n",
      "프리미어리그 팀 중에서는 맨체스터 유나이티드가 65억 5000만 달러(약 8조9636억원)로 전 세계 2위에 올라 가장 높았다. 맨유는 레알과 함께 60억 달러 이상의 가치를 지닌 구단으로 조사됐다.\n",
      "3위는 레알의 영원한 라이벌 바르셀로나로 56억 달러(약 7조6636억원)였다. 4위는 리버풀이었다. 53억 7000만 달러(약 7조3488억원)로 프리미어리그 팀 중에서는 2위에 해당했다. 5위는 프리미어리그 최초 4회 연속 우승에 빛나는 맨체스터 시티로 51억 달러(약 6조9793억원)의 가치를 지닌 것으로 평가됐다. 독일 분데스리가에서 유일하게 선정된 바이에른 뮌헨이 50억 달러(약 6조8425억원)로 6위에 올랐다.\n",
      "TOP 10 목록을 보면 토트넘만 유일하게 최근까지 우승컵을 들어올리지 못한 팀인 걸 알 수 있다. 토트넘보다 낮게 평가된 첼시는 2020-21시즌 유럽축구연맹(UEFA) 챔피언스리그에서 우승했고, 아스널 또한 2019-20시즌 FA컵을 제패했다. 토트넘이 마지막으로 우승한 건 2007-08시즌으로 벌써 16년이 흘렀다.\n",
      "이번 시즌에는 개막 후 10경기 연속 무패(8승2무)를 달리며 무관에서 탈출할 것으로 기대를 모았지만 이후 급격하게 힘이 빠지며 결국 5위로 시즌을 마무리했다.\n",
      "영국 트리뷰나는 \"세계에서 가장 가치 있는 클럽이 공개됐다. 토트넘이 아스널보다 더 높은 순위에 랭크됐다\"라고 놀라워했다.\n",
      "매체는 \"레알이 3년 연속 1위에 오르며 타의 추종을 불허하는 성과를 냈다. 맨유가 2위에 올랐고, 바르셀로나, 리버풀, 맨시티가 뒤를 이었다. 놀랍게도 토트넘은 아스널보다 높은 8위에 올랐다\"라며 우승컵이 없는 토트넘이 8위에 오른 사실을 조명했다.\n",
      "토트넘이 8위에 오를 수 있었던 건 다른 리그보다 월등히 높은 프리미어리그 중계권료 덕분이었다. 포브스는 \"세계에서 가장 가치 있는 축구 클럽 30팀 중 12팀이 프리미어리그 소속이다. 프리미어리그는 2025-26시즌부터 2028-29시즌까지 연평균 21억 달러에 TV 중계권 계약을 체결했다. 다른 축구 리그보다 국내 방송 수익이 2배 이상 많다. 국제 방송 계약까지 포함하면 2위 라리가보다 2배나 더 많다\"라고 분석했다.\n",
      "사진=연합뉴스, 트리뷰나\n",
      "나승우 기자 winright95@xportsnews.com \n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524104635723\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    title = soup.find(\"h3\", class_=\"tit_view\")\n",
    "    print(title.string)\n",
    "\n",
    "    writer = soup.find(\"span\",class_=\"txt_info\")\n",
    "    print(writer.string)\n",
    "\n",
    "    cTime = soup.find(\"span\",class_=\"num_date\")\n",
    "    print(cTime.string)\n",
    "\n",
    "    paragraph1 = soup.find(\"p\",{\"dmcf-pid\":\"B6UyjcWA3u\"})\n",
    "    print(paragraph1.string)\n",
    "\n",
    "    contents = soup.find_all(\"p\",{\"dmcf-ptype\":\"general\"})\n",
    "    for content in contents:\n",
    "        print(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
